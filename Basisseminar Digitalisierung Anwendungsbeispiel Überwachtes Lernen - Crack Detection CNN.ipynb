{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"wzl_rwth.png\" style=\"padding-left: 20px; float: right;\" />\n",
    "\n",
    "<h1 style=\"color: blue;\">Basisseminar Digitalisierung</h1>\n",
    "<h2 style=\"color: #D7A5F4;\">Anwendungsbeispiel Überwachtes Lernen <br /> Binary Crack Detection</h2>\n",
    "<h3> Beispiel aus der Fertigung: Erkennen von Rissen auf Oberflächen von Werkstücken</h3>\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Generelle Anmerkungen*\n",
    "- Eine Code-Zelle kann ausgeführt werden, indem man in die Zelle klickt und dann *STRG* & *Enter* drückt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probemstellung\n",
    "Im ersten Notebook ging es um die Erkennung handgeschriebener Zahlen mithilfe eines Künstlichen Neuronalen Netzes. Dieses Notebook beschäftigt sich ebenfalls mit Bildern, allerdings handelt es hierbei um ein binäres Klassifizierungsproblem, die Bilder werden also nur in zwei verschiedene Klassen eingeteilt (im Gegensatz zum Zahlenbeispiel, wo es 9 verschiedene Klassen gab). Hierbei geht es um ein vereinfachtes Szenario welches so auch in der Fertigung auftritt: Auf Basis eines Bildes von der Oberfläche eines Werkstücks, soll automatisch beurteilt werden, ob dieses offensichtliche Defekte, wie beispielsweise einen Riss aufweist. Das bedeutet, im Folgenden soll ein Künstliches Neuronales Netz trainiert werden, welches in der Lage sein soll, ein Bild entweder zur Klasse \"Defekt - Riss\" oder zur Klasse \"Kein Defekt\" zuzuordnen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erster Schritt - Bibliothek\n",
    "Als erstes müssen wieder einige Code-Bibliothek importiert werden, die unter anderem diverse Bauteile, welche für die Erstellung eines Künstlichen Neuronalen Netzes verwendet werden können, in Form von Methoden bereitstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "# dynamische allocation von gpu memory für den fall das tensorflow-gpu benutzt wird\n",
    "#config = tf.compat.v1.ConfigProto(allow_soft_placement=False)\n",
    "#config.gpu_options.allow_growth = True\n",
    "#session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "# display tensorflow version\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zweiter Schritt - Hilfsmethoden definieren und Daten einlesen\n",
    "Zusätzlich zu den in der obigen Zelle importierten Code-Bibliotheken kann man weitere Methoden definieren, um den eigentlichen Arbeitsablauf besser zu strukturieren und um den Code übersichtlicher zu gestalten. <br />\n",
    "Im ersten Notebook wurden die Daten aus einer zuvor importierten Bibliothek geladen und konnten deshalb quasi ohne Weiteres benutzt werden. In der Realität ist es aber in den allermeisten Fällen so, dass die Daten erst einmal richtig eingelesen und aufbereitet werden müssen, bevor man sie für die eigentliche Klassifizierungsaufgabe verwenden kann. Aus diesem Grund definiert die folgende Zelle Hilfsmethoden, welche dazu genutzt werden können, einen Datensatz Bild für Bild einzulesen. Dabei wird die Größe von jedem Bild an *IMG_SIZE* angepasst. Wie bereits im ersten Notebook erläutert, benötigt man in einem voll verbundenen Künstlichen Neuronalen Netz einen Input-Knoten für jeden Pixel des Bildes, welches man dem Netz zeigen möchte. Da die Bilder im gegebenen Datensatz 227x227 Pixel groß sind, bräuchte man also (nach \"Ausrollen\" der Pixelwerte in einen Vektor) 51.529 Knoten in der Input Layer. Weil dadurch der Rechenaufwand stark steigt, wird jedes Bild verkleinert, um dem Netz insgesamt weniger Informationen zeigen zu müssen. Dazu korrespondierend kann über die Variable *NUMBER_OF_IMAGES_PER_CLASS* festgelegt werden wie viele der Bilder aus unserem Datensatz verwendet werden sollen um das neuronale Netz zu klassifizieren. Generell gilt natürlich: Je mehr verschiedene Beispiele dem Netz zum Lernen gezeigt werden können, desto besser, allerdings steigt dadurch natürlich auch die dafür benötigte Zeit. Deshalb wurde an dieser Stelle die Anzahl auf 3000 Bilder pro Klasse beschränkt.<br />\n",
    "Des Weiteren ist die Farbe der Bilder für die Klassifizierung \"Riss oder kein Riss auf der Oberfläche\" für unseren Fall irrelevant, weshalb weitere Informationen (die wiederum Rechenaufwand bedeuten) dadurch eingegespart werden können, wenn das Bild statt in Farbe, in Graustufen verwendet wird. <br />\n",
    "Außerdem übernehmen die unten angegebenen Hilfsmethoden Aufgaben wie z. B. das korrekte Gruppieren der Daten in Bilder und zugehörige Label (also Riss bzw. kein Riss), sowie das Anzeigen eines Bildes mit dem assoziierten Label. <br />\n",
    "All diese Methoden können im weiteren Verlauf einfach benutzt werden, ohne sich Gedanken über die eigentliche Funktionsweise machen zu müssen, können also als eine Art Bauteil betrachtet werden, welches uns zur Verfügung steht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hilfsfunktionen import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um nun den Datensatz einzulesen und aufzubereiten reicht jetzt ein einfacher Aufruf der zuvor definierten Hilfsmethoden, welche alle nötigen Aufgaben übernehmen. <br />\n",
    "Als Ergebnis erhält man dann einen Datensatz zum Trainieren und einen zum Testen, welcher wiederum in Bild und Label aufgeteilt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = preprocessData()\n",
    "\n",
    "data_X, data_y = prepareXandY(data_train)\n",
    "data_X_test, data_y_test = prepareXandY(data_test)\n",
    "\n",
    "#normalize data tf.keras.utils.normalize(data, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um ein besseres Verständnis für die Problemstellung zu bekommen, kann man sich die Bilder, welche klassifiziert werden sollen visualisieren und das zugehörige Label anzeigen lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayImageAndLabelOfData(data_train, start_index=0, shape=(3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dritter Schritt - Neuronales Netzwerk\n",
    "Im Folgenden ist es Ihre Aufgabe, ein Künstliches Neuronales Netz zu entwerfen, welches möglichst genau Bilder in die zwei Klassen \"Defekt - Riss\" & \"Nicht Defekt\" unterteilen kann. Hierzu sollten Sie sich an der im ersten Notebook dokumentierten Architekturen orientieren.\n",
    "<img src=\"sequential_model.png\" style=\"width: 492px; height: 322px\"/>\n",
    "In der Code-Zelle unter diesem Bild befindet sich ein Code-Grundgerüst, welches ergänzt werden muss, um ein funktionierendes Künstliches Neuronales Netz erzeugen zu können. <br />\n",
    "Dabei kann beispielsweise sowohl mit der Anzahl der Hidden-Layers als auch mit der Anzahl der Knoten experimentiert werden, in dem man das Netz jedes mal, nachdem die Struktur verändert wurde, neu trainiert und dabei die sich ändernde *accuracy* im Blick behält."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###  PLAYGROUND\n",
    "###\n",
    "\n",
    "# ANFANG MODELL DEFINITION\n",
    "model = Sequential()\n",
    "model.add(Flatten())\n",
    "\n",
    "## HIER KÖNNEN LAYERS HINZUGEFÜGT UND/ODER ENTFERNT WERDEN SOWIE DIE ANZAHL DER KNOTEN PRO LAYER VARIIERT WERDEN\n",
    "# bsp: model.add(Dense(#ANZAHL KNOTEN, activation=tf.nn.relu))\n",
    "\n",
    "\n",
    "# ENDE MODELL TRAINIEREN\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x=data_X, y=data_y, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Testen\n",
    "Wie bereits im Vortrag und im ersten Notebook erläutert, wird das Künstliche Neuronale Netz nur mit einem Teil der Daten “trainiert” und mit einem (dem Netz unbekannten) Teil der Daten “getestet”. Damit vermeidet man, dass das Modell einfach nur die Daten abspeichert, ohne eine “echte” Systematik zu lernen (“Overfitting”). Deshalb muss nun getestet werden, ob die Genauigkeit (accuracy) die beim Trainieren erreicht wurde sich auch in den Test-Daten widerspiegelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makePredictionsAndCalculateAccuracy(model, data_X_test, data_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dinge die an dieser Stelle **zu beachten** sind:\n",
    "<ul style=\"list-style-type:disc;\">\n",
    "    <li>Steigt die Genauigkeit des Netzes beim Trainieren pro Epoche erst an und sinkt ab einer gewissen Epochen-Anzahl wieder? -> Anzahl Epochen verringern.</li>\n",
    "    <li>Ist die Genauigkeit des Netzes beim Trainieren deutlich höher als auf dem Test-Datensatz? -> Das Netz overfittet die Daten. Mögliche Lösungen: Anzahl der Layers/Knoten pro Layer verringern; Anzahl Epochen verringern.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vergleich - Mensch vs Maschine\n",
    "Im Folgenden werden nun ein paar Bilder angezeigt, welche von Ihnen selbst klassifiziert werden müssen. Dazu können Sie einfach in das dabei erscheinende Feld klicken und dort entweder \"Ja\" oder \"Nein\" eintippen. Danach wird Ihre Antwort mit der des Künstlichen Neuronalen Netz verglichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humanVSmachine(model, rounds=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Musterlösung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First approach: Sequential NN\n",
    "#np.random.seed(16)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten())\n",
    "model.add(Dense(508, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(254, activation=tf.nn.relu))\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dense(1, activation=tf.nn.sigmoid))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x=data_X, y=data_y, epochs=5)\n",
    "\n",
    "makePredictionsAndCalculateAccuracy(model, data_X_test, data_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better approach convolutional NN\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (5,5), input_shape=data_X.shape[1:], activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "model.fit(x=data_X, y=data_y, epochs=2)\n",
    "\n",
    "makePredictionsAndCalculateAccuracy(model, data_X_test, data_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
