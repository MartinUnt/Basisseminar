{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"wzl_rwth.png\" style=\"padding-left: 20px; float: right;\" />\n",
    "\n",
    "<h1 style=\"color: blue;\">Basisseminar Digitalisierung</h1>\n",
    "<h2 style=\"color: #D7A5F4;\">Anwendungsbeispiel Überwachtes Lernen: <br /> Erkennung von per Hand geschriebenen Zahlen mithilfe eines Künstlichen Neuronalen Netzes</h2>\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Generelle Anmerkungen*\n",
    "- Eine Code-Zelle kann ausgeführt werden, indem man auf die jeweilige Zelle klickt und dann *STRG* & *Enter* drückt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probemstellung\n",
    "In diesem Notebook geht es um die Grundlagen von Künstlichen Neuronalen Netzen, welche anhand eines Anwendungsbeispiels aus dem Bereich des Überwachten Lernens verdeutlicht werden. Hierzu wird von Grund auf ein neuronales Netz aufgebaut, welches dazu in der Lage sein soll per Hand geschriebene Zahlen zu erkennen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erster Schritt - Bibliothek\n",
    "Als erstes müssen einige Code-Bibliotheken importiert werden, die unter anderem diverse Bauteile, welche für die Erstellung eines Neuronalen Netzes bentutzt werden können, bereitstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "#Import of tensorflow and quick version test\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "print(tf.__version__)\n",
    "\n",
    "# Dynamische Allokation von GPU Memory für den Fall, dass TensorFlow-GPU benutzt\n",
    "#config = tf.compat.v1.ConfigProto(allow_soft_placement=False)\n",
    "#config.gpu_options.allow_growth = True\n",
    "#session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "#Import of matplotlib for visualization purposes\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "#import numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zweiter Schritt - Daten\n",
    "Als nächstes kann die zuvor importierte Code-Bibliothek dazu genutzt werden, einen Beispieldatensatz zu importieren. In diesem Anwendungsbeispiel benutzen wir einen Datensatz, welcher Daten handgeschriebenen Zahlen enthält. <br />\n",
    "Die Zahlen werden dabei durch Bilder mit 28x28 Pixeln repräsentiert, welchen jeweils ein Label von 0 bis 9 zugeordnet wird (je nachdem ob auf das Bild für eine 0, 1, 2 usw. steht)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Danach müssen die Daten in einen Trainings- sowie Testdatensatz unterteilt werden. Wie bereits im Vortrag erläutert, wird das Künstliche Neuronale Netz nur mit einem Teil der Daten “trainiert” und mit einem (dem Netz unbekannten) Teil der Daten “getestet”. Damit vermeidet man, dass das Modell einfach nur die Daten abspeichert, ohne eine “echte” Systematik zu lernen (“Overfitting”). <br />\n",
    "Testet man das Netz auf den gleichen Daten, auf denen man auch trainiert hat, führt dies einfach nur dazu, dass das Netz die Label der einzelnen Datenpunkte speichert anstatt die zu Grunde liegende Struktur dahinter zu erkennen, was für eine Generalisierung notwendig wäre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(numbers_train, number_labels_train), (numbers_test, number_labels_test) = data.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um ein besseres Gefühl für die Daten zu bekommen, kann man sich eine Zahl sowie das dazugehörige Label aus dem Trainingsdatensatz visualisieren lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eine Zahl aus dem Trainingsdatensatz:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Das zugehörige Label lautet:  5\n"
     ]
    }
   ],
   "source": [
    "print(\"Eine Zahl aus dem Trainingsdatensatz:\")\n",
    "pyplot.imshow(numbers_train[0], cmap=pyplot.cm.binary)\n",
    "pyplot.show()\n",
    "\n",
    "print(\"Das zugehörige Label lautet: \", number_labels_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dritter Schritt - Neuronales Netzwerk\n",
    "Nachdem die Daten zum Trainieren des Künstlichen Neuronalen Netzes nun in den Speicher geladen sind und wir darauf zugreifen können, können wir als Nächstes mithilfe der anfangs importierten Code-Bibliothek ein Netz konstruieren. <br />\n",
    "Als Erstes muss man den Typ des Models festlegen. In diesem Beispiel benutzen wir das im Vortrag vorgestellte Netz (ein so genanntes sequentielles Künstliches Neuronales Netz).\n",
    "<img src=\"sequential_model.png\" style=\"width: 659px; height: 431px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da die Bilder der Zahlen jeweils 28x28 Pixel haben, also zwei Dimensionen besitzen (Höhe und Breite), das oben abgebildete Netzwerk allerdings nur eine Dimension in dem Input-Layer besitzt (vektorförmig), müssen die Daten \"flach\" gemacht werden. Die Daten der Form 28x28 erhalten somit die Form 1x784. Dazu kann ganz einfach ein \"Flatten layer\" (Bauteil \"Flatten()\") benutzt werden, die wir unserem Modell als erstes per \"add\" hinzufügen. Dabei kann man sich vorstellen, dass man die 28x28 = 784 Pixel \"ausrollt\" in einen Vektor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Danach muss man sich darüber Gedanken machen, wie man die Hidden-Layers aufbauen möchte. In dem oben abgebildeten Netz ist gut zu erkennen, dass die einzelnen Knoten dicht (eng.: dense) miteinander verknüpft sind. Der Ouput eines Knoten in dem \"hidden layer 1\" dient also als partieller Input für alle Knoten in der \"hidden layer 2\". <br />\n",
    "Dies lässt sich mit dem Bauteil \"Dense()\" aus der Bibliothek darstellen. <br />\n",
    "Des Weiteren muss man sich überlegen aus wie vielen Knoten die Hidden-Layers jeweils bestehen sollen. Dies kann als Parameter an das dense-Bauteil weitergegeben werden. <br />\n",
    "Da jeder Knoten die gewichteten Outputs der Ebene davor erhält, muss zusätzlich auch eine sogenannte Activation-Function angegeben werden, welche dafür verantwortlich ist, wann und was ein einzelner Knoten der Layer \"feuert\". Die hier verwendete Funktion \"relu\" erhält die Inputs eines Knotens und gibt 0 zurück, wenn der Input kleiner/gleich 0 ist, andernfalls wird einfach der Input zurückgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dense(128, activation=tf.nn.relu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Schluss muss dann noch ein Ouput-Layer definiert werden. Dieses ist, wie oben im Bild des Netzwerks zu erkennen, ebenfalls *dense*. Allerdings unterscheidet es sich unter anderem in der Anzahl der Knoten von den anderen Layern. Da in diesem Beispiel Daten in 10 Klassen unterteilt und klassifiziert werden, nämlich in die Zahlen von 0-9, werden auch genau 10 Knoten in dieser letzten Layer benötigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um dem Netz nun mitzuteilen, wie genau die Optimierung ablaufen soll, müssen dem Bauteil compile() diverse Parameter übergeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vierter Schritt - Netzwerk trainieren und testen\n",
    "Nachdem das Netzwerk nun komplett definiert ist, kann mit dem Training begonnen werden. <br />\n",
    "Dazu kann einfach die fit() Methode aufgerufen werden, welche als Parameter die Trainingsdaten sowie die Anzahl der Epochen (wie oft über die Trainingsdaten iteriert werden soll, also wie oft das Netzwerk jedes Bild während des Trainings sehen soll) erwartet. <br />\n",
    "Danach übernimmt die Bibliothek alle weiteren der 6 auf den Folien angesprochenen Trainingsschritte und es muss nur noch darauf gewartet werden, dass das Training vollständig absolviert wurde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 10s 170us/sample - loss: 1.6587 - accuracy: 0.8692 - val_loss: 0.6453 - val_accuracy: 0.8890\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.3616 - accuracy: 0.9226 - val_loss: 0.3383 - val_accuracy: 0.9222\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2625 - accuracy: 0.9378 - val_loss: 0.2377 - val_accuracy: 0.9439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d7ae0e45f8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(numbers_train, number_labels_train, epochs=3,\n",
    "         validation_data = (numbers_test, number_labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem das Netz nun trainiert wurde und bereits eine gute Genauigkeit aufweist, können wir das Netz mit den Daten, die wir am Anfang als Testdaten zur Seite gelegt haben, testen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#error, acc = model.evaluate(numbers_test, number_labels_test)\n",
    "#print(f\"Error auf Testdaten {error} & Accuracy auf Testdaten {acc}\")\n",
    "\n",
    "predictions = model.predict(numbers_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um diese Vorhersagen des trainierten Netzes zu überprüfen, kann man einzelne Vorhersagen per Hand sichten. Das erste Bild einer handschriftlichen Zahl, welches dem Netz zur Klassifikation übergeben wurde, sieht wie folgt aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pyplot.imshow(numbers_test[0], cmap=pyplot.cm.binary)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn man sich jetzt anguckt, wie die Vorhersagen aufgebaut sind, erkennt man, dass die einzelnen Knoten in dem Output-Layer jeweils eine Wahrscheinlichkeit für das zugehörige Label, bzw. die Zahl für welche das Label steht, darstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um herauszufinden, welche dieser Wahrscheinlichkeiten am höchsten ist, also welche Zahl das Netz zu erkennen glaubt, kann man einfach das maximale Element nehmen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Netz hat also die Zahl richtig erkannt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ausblick\n",
    "Neben einfach sequenziellen und \"dicht\" verknüpften Künstlichen Neuronalen Netz (jedes Neuron einer Schicht ist mit jedem Neuron der folgenden Schicht verknüpft) gibt es auch noch weitere Strukturen, die meist auf bestimmte Anwendungen spezialisiert sind. Beispielsweise verwendet man bei der Klassifizierung von Bildern oftmals sogenannte Convolutional Neural Networks. <br />\n",
    "Hier wird nicht direkt zu Beginn ein Flatten-Layer angewendet, welches alle Bildpixel direkt einem Inputknoten zuordnet, stattdessen wird versucht sogenannte *Feature Maps* auf dem Bild zu berechnen. Dabei wird eine Art Schablone (Kernel) über das Bild gelegt und beim Verschieben mit diesem verrechnet. Auf diese Weise können je nach Kernel unterschiedliche Bildmerkmale verdeutlicht werden, wie zum Beispiel Kanten, Ecken oder andere Merkmale. <br />\n",
    "In der Animation unter diesem Text ist dies beispielhaft an einem Kernel der Größe (3, 3) verdeutlicht. Das Bild (links) wird mit dem Kernel in der Mitte verrechnet und ergibt die *Feature Map* (rechts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: block; margin-left: auto; margin-right: auto;\"><img src=\"https://s3-us-west-2.amazonaws.com/static.pyimagesearch.com/keras-conv2d/keras_conv2d_padding.gif\" alt=\"\" width=\"800\" height=\"400\">\n",
    "    <!-- <a href=\"https://stackoverflow.com/questions/52067833/how-to-plot-an-animated-matrix-in-matplotlib\" target=\"_blank\" rel=\"noopener\">\n",
    "        source\n",
    "    </a> -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Berechnung der *Feature Map* ergibt sich dabei wie folgt:\n",
    "\n",
    "<img src=\"convolution_annotated.png\" />\n",
    "\n",
    "Die Pixel werden einfach mit dem Wert des Kernels, welcher sich gerade direkt über diesem Pixel befindet, multipliziert und danach aufaddiert. Dieses Verfahren wird für jede Position des Kernels wiederholt, wie in der Animation zu erkennen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einem nächsten Schritt wird versucht die *Feature Map* zu verkleinern, indem sogenanntes *Max Pooling* angewendet wird. Dabei wird, ähnlich wie bei dem Verfahren oben, eine Schablone über das Bild gelegt und beim Verschieben jeweils der maximale Wert einer ganzen Region als neuer Wert festgelegt.\n",
    "\n",
    "<img src=\"pooling_annotated.png\" />\n",
    "\n",
    "Innerhalb der Region der gelben Schablone ist der maximale Wert 295, weshalb nur noch dieser festgehalten wird, sozusagen als Repräsentant der ganzen Region. Convolutional Neural Networks nutzen dabei aus, dass in Bildern räumliche Zusammenhänge zwischen Pixeln bestehen (zum Beispiel dunklere/hellere Bereiche, die sich zusammenfassen lassen)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ende eines Convolutional Neural Networks besteht wieder aus einem Flatten-Layer, welches unsere immer noch zweidimensionalen Daten wieder in eindimensionale Daten konvertiert (ausrollt), einem dicht verknüpften Layer, gefolgt von einer Output-Layer. Mithilfe der zu Beginn importierten Bibliothek lässt sich auch diese Netzstruktur einfach realisieren. <br />\n",
    "Der erste Parameter von Conv2D bezieht sich dabei auf die Anzahl der Kernels, die benutzt werden soll, der zweite Parameter beschreibt wiederum deren Größe. <br />\n",
    "Analog beschreibt der Parameter von MaxPooling2D die Größe der Schablone, welche während der *Pooling* Phase benutzt werden soll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 13s 211us/sample - loss: 1.0232 - accuracy: 0.7064 - val_loss: 0.0991 - val_accuracy: 0.9723\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 12s 207us/sample - loss: 0.0706 - accuracy: 0.9792 - val_loss: 0.0606 - val_accuracy: 0.9810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d7b3135a90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X = np.array(numbers_train).reshape(-1, 28, 28, 1)\n",
    "data_y = to_categorical(number_labels_train)\n",
    "\n",
    "data_X_test = np.array(numbers_test).reshape(-1, 28, 28, 1)\n",
    "data_y_test = to_categorical(number_labels_test)\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv2D(16, (3,3), input_shape=data_X.shape[1:], activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#model2.add(Dropout(0.1))\n",
    "\n",
    "model2.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model2.add(Flatten())\n",
    "\n",
    "model2.add(Dense(32, activation='relu'))\n",
    "model2.add(Dense(10, activation='sigmoid'))\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "model2.fit(x=data_X, y=data_y, epochs=2, validation_data=(data_X_test, data_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch wenn das zu Beginn trainierte sequenzielle Netz mit 94% schon eine sehr gute Genauigkeit aufweist, erreicht man mit einem Convolutional Neural Net noch einmal bessere Ergebnisse. In der Praxis ist dieser Unterschied meisten außerdem deutlich größer. Außerdem ist bei größeren Bildern die Anzahl der Parameter in einem voll verbundenen Künstlichen Neuronalen Netz viel zu groß."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
